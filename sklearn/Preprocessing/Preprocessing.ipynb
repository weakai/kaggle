{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 标准化\n",
    "\n",
    "- preprocessing.StandardScaler\n",
    "  - 使用 scipy.sparse 可以处理稀疏矩阵\n",
    "- preprocessing.MinMaxScaler\n",
    "- preprocessing.MaxAbsScaler\n",
    "  - 处理稀疏矩阵\n",
    "- RobustScaler\n",
    "  - 处理 outlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "X_train = np.array([[ 1., -1.,  2.],\n",
    "                    [ 2.,  0.,  0.],\n",
    "                    [ 0.,  1., -1.]])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scaler.mean_: [1.         0.         0.33333333]\n",
      "scaler.scale_: [0.81649658 0.81649658 1.24721913]\n"
     ]
    },
    {
     "data": {
      "text/plain": "array([[ 0.        , -1.22474487,  1.33630621],\n       [ 1.22474487,  0.        , -0.26726124],\n       [-1.22474487,  1.22474487, -1.06904497]])"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 标准化 变换后的各维特征有 0 均值，单位方差\n",
    "# 也叫 z-score 规范化），计算方式是将特征值减去均值，除以标准差\n",
    "# 创建一个标准化器，然后拟合 X_train\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "print(f'scaler.mean_: {scaler.mean_}')  # 转化前每个维度的均值\n",
    "print(f'scaler.scale_: {scaler.scale_}')  # 转化前每个维度的方差\n",
    "X_scaled = scaler.transform(X_train)\n",
    "X_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "(array([0., 0., 0.]), array([1., 1., 1.]))"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 转化后每个维度的均值和方差\n",
    "X_scaled.mean(axis=0), X_scaled.std(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.96"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# 创建分类用的数据集\n",
    "X, y = make_classification(random_state=42)\n",
    "# 划分数据\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "\n",
    "# 创建模型（pipe）\n",
    "## 标准化，逻辑回归\n",
    "pipe = make_pipeline(StandardScaler(), LogisticRegression())\n",
    "\n",
    "# 拟合\n",
    "pipe.fit(X_train, y_train)  # apply scaling on training data\n",
    "\n",
    "pipe.score(X_test, y_test)  # apply scaling on testing data, without leaking training data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.40824829, -0.40824829,  0.81649658],\n",
       "       [ 1.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.70710678, -0.70710678]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = [[ 1., -1.,  2.],\n",
    "\t[ 2.,  0.,  0.],\n",
    "\t[ 0.,  1., -1.]]\n",
    "X_normalized = preprocessing.normalize(X, norm='l2')\n",
    "X_normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建一个正则化器，拟合 X\n",
    "normalizer = preprocessing.Normalizer().fit(X)\n",
    "# 正则化 X\n",
    "normalizer.transform(X)\n",
    "# 正则化其他数据\n",
    "normalizer.transform([[-1.,  1., 0.]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoding categorical features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OrdinalEncoder will also passthrough missing values that are indicated by np.nan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 1.]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc = preprocessing.OrdinalEncoder()\n",
    "X = [\n",
    "\t['male', 'from US', 'uses Safari'],\n",
    "\t['female', 'from Europe', 'uses Firefox']\n",
    "\t]\n",
    "enc.fit(X)\n",
    "enc.transform([['female', 'from US', 'uses Safari']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 1., 0., 0., 1.],\n",
       "       [0., 1., 1., 0., 0., 0., 1.]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc = preprocessing.OneHotEncoder()\n",
    "X = [\n",
    "\t['male', 'from US', 'uses Safari'],\n",
    "\t['female', 'from Europe', 'uses Firefox'],\n",
    "\t['male', 'from Europe', 'uses Edge']\n",
    "\t]\n",
    "\n",
    "enc.fit(X)\n",
    "enc.transform([\n",
    "\t['female', 'from US', 'uses Safari'],\n",
    "\t['male', 'from Europe', 'uses Safari']\n",
    "\t]).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array(['female', 'male'], dtype=object),\n",
       " array(['from Europe', 'from US'], dtype=object),\n",
       " array(['uses Edge', 'uses Firefox', 'uses Safari'], dtype=object)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc.categories_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 1., 0., 0., 1., 0., 0., 0.]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genders = ['female', 'male']\n",
    "locations = ['from Africa', 'from Asia', 'from Europe', 'from US']\n",
    "browsers = ['uses Chrome', 'uses Firefox', 'uses IE', 'uses Safari']\n",
    "enc = preprocessing.OneHotEncoder(categories=[genders, locations, browsers])\n",
    "# Note that for there are missing categorical values for the 2nd and 3rd\n",
    "# feature\n",
    "X = [['male', 'from US', 'uses Safari'], ['female', 'from Europe', 'uses Firefox']]\n",
    "enc.fit(X)\n",
    "enc.transform([['female', 'from Asia', 'uses Chrome']]).toarray()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "array([1, 2, 6])\n",
      "array([0, 0, 1, 2])\n",
      "array([1, 1, 2, 6])\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit([1, 2, 2, 6])\n",
    "print(repr(le.classes_))\n",
    "# 转变\n",
    "print(repr(le.transform([1, 1, 2, 6])))\n",
    "# 逆转\n",
    "print(repr(le.inverse_transform([0, 0, 1, 2])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0318ac3bd3f59db66109d50e71bef0a750d226209e5ff62348269391b9fbc17e"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}