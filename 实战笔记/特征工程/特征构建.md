# 特征

## 特征合并

### merge

```python
df = pd.merge(df, df_structure, how = 'left',
                  left_on  = ['molecule_name', f'atom_index_{atom_idx}'],
                  right_on = ['molecule_name',  'atom_index'])
```

### 稀疏矩阵的水平拼接

```python
from scipy.sparse import hstack

# data_tfidf 是二维矩阵
# data_tfidf 是组成信息，缺少长度表征
X2 = hstack(
    (data_tfidf, np.array(data['length'])[:, None])
).A
```

## 特征丢弃

```python
df = df.drop('atom_index', axis=1)
```

## 特征映射

### 离异值排除

```python
train = train[train.item_price < 100000]
train = train[train.item_cnt_day < 1001]
```

### 稀有类排除

- normalize: 非计数值，而是计数百分比

```python
bad_atoms_0 = list(train_type['atom_index_0'].value_counts(normalize=True)[train_type['atom_index_0'].value_counts(normalize=True) < 0.01].index)
bad_atoms_1 = list(train_type['atom_index_1'].value_counts(normalize=True)[train_type['atom_index_1'].value_counts(normalize=True) < 0.01].index)
bad_atoms = list(set(bad_atoms_0 + bad_atoms_1))
train_type = train_type.loc[(train_type['atom_index_0'].isin(bad_atoms_0) == False) & (train_type['atom_index_1'].isin(bad_atoms_0) == False)]
   
```

## 特征选择 降维

```python
# Threshold for removing correlated variables
threshold = 0.95
# Absolute value correlation matrix
corr_matrix = df_train.corr().abs()
# Getting the upper triangle of correlations
upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(np.bool))
# Select columns with correlations above threshold
to_drop = [column for column in upper.columns if any(upper[column] > threshold)]
print('There are %d columns to remove.' % (len(to_drop)))

df_train = df_train.drop(columns = to_drop)
df_test = df_test.drop(columns = to_drop)

print('Training shape: ', df_train.shape)
print('Testing shape: ', df_test.shape)
```

## 特征重命名

```python
df = df.rename(columns={'atom': f'atom_{atom_idx}',
                            'x': f'x_{atom_idx}',
                            'y': f'y_{atom_idx}',
                            'z': f'z_{atom_idx}'})
```

## 特征遍历

### 类别特征按类别中进行遍历

```python
# enmerate(np.arr[typ1,typ2,...])
for i, t in enumerate(df_train['type'].unique()):
    train_type = df_train.loc[df_train['type'] == t]
```

### 遍历各列

```python
for col in df.columns:
        col_type = df[col].dtypes
```
