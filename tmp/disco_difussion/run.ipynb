{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess, os, sys, ipykernel\n",
    "\n",
    "def gitclone(url):\n",
    "    res = subprocess.run(['git', 'clone', url], stdout=subprocess.PIPE).stdout.decode('utf-8')\n",
    "    print(res)\n",
    "\n",
    "def pipi(modulestr):\n",
    "    res = subprocess.run(['pip', 'install', modulestr], stdout=subprocess.PIPE).stdout.decode('utf-8')\n",
    "    print(res)\n",
    "\n",
    "def pipie(modulestr):\n",
    "    res = subprocess.run(['git', 'install', '-e', modulestr], stdout=subprocess.PIPE).stdout.decode('utf-8')\n",
    "    print(res)\n",
    "\n",
    "def wget(url, outputdir):\n",
    "    res = subprocess.run(['wget', url, '-P', f'{outputdir}'], stdout=subprocess.PIPE).stdout.decode('utf-8')\n",
    "    print(res)\n",
    "\n",
    "try:\n",
    "    from google.colab import drive\n",
    "    print(\"Google Colab detected. Using Google Drive.\")\n",
    "    is_colab = True\n",
    "    #@markdown If you connect your Google Drive, you can save the final image of each run on your drive.\n",
    "    google_drive = True #@param {type:\"boolean\"}\n",
    "    #@markdown Click here if you'd like to save the diffusion model checkpoint file to (and/or load from) your Google Drive:\n",
    "    save_models_to_google_drive = True #@param {type:\"boolean\"}\n",
    "except:\n",
    "    is_colab = False\n",
    "    google_drive = False\n",
    "    save_models_to_google_drive = False\n",
    "    print(\"Google Colab not detected.\")\n",
    "\n",
    "if is_colab:\n",
    "    if google_drive is True:\n",
    "        drive.mount('/content/drive')\n",
    "        root_path = '/content/drive/MyDrive/AI/Disco_Diffusion'\n",
    "    else:\n",
    "        root_path = '/content'\n",
    "else:\n",
    "    root_path = os.getcwd()\n",
    "\n",
    "import os\n",
    "def createPath(filepath):\n",
    "    os.makedirs(filepath, exist_ok=True)\n",
    "\n",
    "initDirPath = f'{root_path}/init_images'\n",
    "createPath(initDirPath)\n",
    "outDirPath = f'{root_path}/images_out'\n",
    "createPath(outDirPath)\n",
    "\n",
    "if is_colab:\n",
    "    if google_drive and not save_models_to_google_drive or not google_drive:\n",
    "        model_path = '/content/models'\n",
    "        createPath(model_path)\n",
    "    if google_drive and save_models_to_google_drive:\n",
    "        model_path = f'{root_path}/models'\n",
    "        createPath(model_path)\n",
    "else:\n",
    "    model_path = f'{root_path}/models'\n",
    "    createPath(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib, shutil, os, sys\n",
    "if not is_colab:\n",
    "    # If running locally, there's a good chance your env will need this in order to not crash upon np.matmul() or similar operations.\n",
    "    os.environ['KMP_DUPLICATE_LIB_OK']='TRUE'\n",
    "\n",
    "PROJECT_DIR = os.path.abspath(os.getcwd())\n",
    "USE_ADABINS = True\n",
    "\n",
    "if is_colab:\n",
    "  if google_drive is not True:\n",
    "    root_path = f'/content'\n",
    "    model_path = '/content/models' \n",
    "else:\n",
    "  root_path = os.getcwd()\n",
    "  model_path = f'{root_path}/models'\n",
    "\n",
    "model_256_downloaded = False\n",
    "model_512_downloaded = False\n",
    "model_secondary_downloaded = False\n",
    "\n",
    "multipip_res = subprocess.run(['pip', 'install', 'lpips', 'datetime', 'timm', 'ftfy', 'einops', 'pytorch-lightning', 'omegaconf'], stdout=subprocess.PIPE).stdout.decode('utf-8')\n",
    "print(multipip_res)\n",
    "\n",
    "if is_colab:\n",
    "  subprocess.run(['apt', 'install', 'imagemagick'], stdout=subprocess.PIPE).stdout.decode('utf-8')\n",
    "\n",
    "try:\n",
    "  from CLIP import clip\n",
    "except:\n",
    "  if not os.path.exists(\"CLIP\"):\n",
    "    gitclone(\"https://github.com/openai/CLIP\")\n",
    "  sys.path.append(f'{PROJECT_DIR}/CLIP')\n",
    "\n",
    "try:\n",
    "  from guided_diffusion.script_util import create_model_and_diffusion\n",
    "except:\n",
    "  if not os.path.exists(\"guided-diffusion\"):\n",
    "    gitclone(\"https://github.com/crowsonkb/guided-diffusion\")\n",
    "  sys.path.append(f'{PROJECT_DIR}/guided-diffusion')\n",
    "\n",
    "try:\n",
    "  from resize_right import resize\n",
    "except:\n",
    "  if not os.path.exists(\"ResizeRight\"):\n",
    "    gitclone(\"https://github.com/assafshocher/ResizeRight.git\")\n",
    "  sys.path.append(f'{PROJECT_DIR}/ResizeRight')\n",
    "\n",
    "try:\n",
    "  import py3d_tools\n",
    "except:\n",
    "  if not os.path.exists('pytorch3d-lite'):\n",
    "    gitclone(\"https://github.com/MSFTserver/pytorch3d-lite.git\")\n",
    "  sys.path.append(f'{PROJECT_DIR}/pytorch3d-lite')\n",
    "\n",
    "try:\n",
    "  from midas.dpt_depth import DPTDepthModel\n",
    "except:\n",
    "  if not os.path.exists('MiDaS'):\n",
    "    gitclone(\"https://github.com/isl-org/MiDaS.git\")\n",
    "  if not os.path.exists('MiDaS/midas_utils.py'):\n",
    "    shutil.move('MiDaS/utils.py', 'MiDaS/midas_utils.py')\n",
    "  if not os.path.exists(f'{model_path}/dpt_large-midas-2f21e586.pt'):\n",
    "    wget(\"https://github.com/intel-isl/DPT/releases/download/1_0/dpt_large-midas-2f21e586.pt\", model_path)\n",
    "  sys.path.append(f'{PROJECT_DIR}/MiDaS')\n",
    "\n",
    "try:\n",
    "  sys.path.append(PROJECT_DIR)\n",
    "  import disco_xform_utils as dxf\n",
    "except:\n",
    "  if not os.path.exists(\"disco-diffusion\"):\n",
    "    gitclone(\"https://github.com/alembics/disco-diffusion.git\")\n",
    "  if os.path.exists('disco_xform_utils.py') is not True:\n",
    "    shutil.move('disco-diffusion/disco_xform_utils.py', 'disco_xform_utils.py')\n",
    "  sys.path.append(PROJECT_DIR)\n",
    "\n",
    "import torch\n",
    "from dataclasses import dataclass\n",
    "from functools import partial\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import gc\n",
    "import io\n",
    "import math\n",
    "import timm\n",
    "from IPython import display\n",
    "import lpips\n",
    "from PIL import Image, ImageOps\n",
    "import requests\n",
    "from glob import glob\n",
    "import json\n",
    "from types import SimpleNamespace\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "import torchvision.transforms as T\n",
    "import torchvision.transforms.functional as TF\n",
    "from tqdm.notebook import tqdm\n",
    "from CLIP import clip\n",
    "from resize_right import resize\n",
    "from guided_diffusion.script_util import create_model_and_diffusion, model_and_diffusion_defaults\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from ipywidgets import Output\n",
    "import hashlib\n",
    "from functools import partial\n",
    "if is_colab:\n",
    "  os.chdir('/content')\n",
    "  from google.colab import files\n",
    "else:\n",
    "  os.chdir(f'{PROJECT_DIR}')\n",
    "from IPython.display import Image as ipyimg\n",
    "from numpy import asarray\n",
    "from einops import rearrange, repeat\n",
    "import torch, torchvision\n",
    "import time\n",
    "from omegaconf import OmegaConf\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "# AdaBins stuff\n",
    "if USE_ADABINS:\n",
    "  try:\n",
    "    from infer import InferenceHelper\n",
    "  except:\n",
    "    if os.path.exists(\"AdaBins\") is not True:\n",
    "      gitclone(\"https://github.com/shariqfarooq123/AdaBins.git\")\n",
    "    if not os.path.exists(f'{PROJECT_DIR}/pretrained/AdaBins_nyu.pt'):\n",
    "      createPath(f'{PROJECT_DIR}/pretrained')\n",
    "      wget(\"https://cloudflare-ipfs.com/ipfs/Qmd2mMnDLWePKmgfS8m6ntAg4nhV5VkUyAydYBp8cWWeB7/AdaBins_nyu.pt\", f'{PROJECT_DIR}/pretrained')\n",
    "    sys.path.append(f'{PROJECT_DIR}/AdaBins')\n",
    "  from infer import InferenceHelper\n",
    "  MAX_ADABINS_AREA = 500000\n",
    "\n",
    "import torch\n",
    "DEVICE = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', DEVICE)\n",
    "device = DEVICE # At least one of the modules expects this name..\n",
    "\n",
    "if torch.cuda.get_device_capability(DEVICE) == (8,0): ## A100 fix thanks to Emad\n",
    "  print('Disabling CUDNN for A100 gpu', file=sys.stderr)\n",
    "  torch.backends.cudnn.enabled = False"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "762112e6b34bc8316202017048d551b756b3c2877c7cac6fe05ea8d61b022941"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 ('disco')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
